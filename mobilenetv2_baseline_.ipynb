{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet50_.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1QB8Kzd3YjBfLFX61SRlxEW3ENiDeHuCV",
      "authorship_tag": "ABX9TyOAsMoDMIoCHiDva9IEsJTQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b0fb1ca7da644e53bbd6e55178eff1f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f33da9131af240b9b43bf6f900a8b578",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3bee99105c014128b1361dbc546617d5",
              "IPY_MODEL_973f99c5c13e402e8bfaadce782f3c4b",
              "IPY_MODEL_9bb5a01b8ba14e20b5604878672477b0"
            ]
          }
        },
        "f33da9131af240b9b43bf6f900a8b578": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3bee99105c014128b1361dbc546617d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9941af77058044cc9ac3607c4da2d557",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fc5680a472004a298874666228ac7018",
              "IPY_MODEL_975673260de1444ba1a3981ea47e3995"
            ]
          }
        },
        "973f99c5c13e402e8bfaadce782f3c4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_31082019486749e3980d3ae419ddaf79",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_250a340b1a7646338aac811d149534cf",
              "IPY_MODEL_f8214b5cc8004a1c97be04ba577b49e7"
            ]
          }
        },
        "9bb5a01b8ba14e20b5604878672477b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9c2f2e023caf41f1969731fa45c5071e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "        14 iter, 2 epoch / 2 epochs<br />   0.81434 iters/sec. Estimated time to finish: 0:00:00.",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a2a81540b23475999331ef3c52dd012"
          }
        },
        "9941af77058044cc9ac3607c4da2d557": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc5680a472004a298874666228ac7018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_106197aabbf444d98df8c0d87ffccbe8",
            "_dom_classes": [],
            "description": "total",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e0bee1ddbf2547378a658414f616288c"
          }
        },
        "975673260de1444ba1a3981ea47e3995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8d738215d4df46619b8e38cedd544479",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100.00%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6993d57ad824ec58ef1a931c44fec02"
          }
        },
        "31082019486749e3980d3ae419ddaf79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "250a340b1a7646338aac811d149534cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e4164d82b76648208cd7612081f7a97b",
            "_dom_classes": [],
            "description": "this epoch",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3263c840b5a646d49b7eec0dc05ed88c"
          }
        },
        "f8214b5cc8004a1c97be04ba577b49e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1bad5529215d4d3591ca5e6db2027ed9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.00%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a640772fbee34f19bf76cfc0140e083d"
          }
        },
        "9c2f2e023caf41f1969731fa45c5071e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a2a81540b23475999331ef3c52dd012": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "106197aabbf444d98df8c0d87ffccbe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e0bee1ddbf2547378a658414f616288c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d738215d4df46619b8e38cedd544479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6993d57ad824ec58ef1a931c44fec02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4164d82b76648208cd7612081f7a97b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3263c840b5a646d49b7eec0dc05ed88c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1bad5529215d4d3591ca5e6db2027ed9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a640772fbee34f19bf76cfc0140e083d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "56a71fb57eb744f39ee99f7ee4d3f1ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_01cb0aa70102447b93463cfcb9b7dda8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>iteration</th>\n      <th>main/loss</th>\n      <th>main/nll</th>\n      <th>validation/main/loss</th>\n      <th>validation/main/nll</th>\n      <th>lr</th>\n      <th>elapsed_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>5368.75863</td>\n      <td>5368.75863</td>\n      <td>4216.005014</td>\n      <td>4216.005014</td>\n      <td>0.001</td>\n      <td>12.336409</td>\n    </tr>\n  </tbody>\n</table>",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_da82d683ad82442bbeb85ea3a1a9fdc8"
          }
        },
        "01cb0aa70102447b93463cfcb9b7dda8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "da82d683ad82442bbeb85ea3a1a9fdc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emanuel-sol/CS4476-Project/blob/master/mobilenetv2_baseline_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5DHOTg-XQsB",
        "outputId": "b6f1b31b-64eb-49fd-fc0b-00bd6769c3b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import zipfile\n",
        "!pip install -q kaggle\n",
        "!pip install pytorch-pfn-extras==0.3.1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Collecting pytorch-pfn-extras==0.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/f2/234ae2d89fde3a29c93fe04040bfd45b1a36dac7ef9188de736066d90bff/pytorch-pfn-extras-0.3.1.tar.gz (85kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pfn-extras==0.3.1) (1.18.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pytorch-pfn-extras==0.3.1) (1.7.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->pytorch-pfn-extras==0.3.1) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->pytorch-pfn-extras==0.3.1) (0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->pytorch-pfn-extras==0.3.1) (3.7.4.3)\n",
            "Building wheels for collected packages: pytorch-pfn-extras\n",
            "  Building wheel for pytorch-pfn-extras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-pfn-extras: filename=pytorch_pfn_extras-0.3.1-cp36-none-any.whl size=99756 sha256=7f9410317539e88a34ee8c10d0135a7582d640373d2c4e742a1b512d4c189708\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/b5/47/ad130698bff3c758cc1be7d78b0ed35e54cee7d4f40b695c72\n",
            "Successfully built pytorch-pfn-extras\n",
            "Installing collected packages: pytorch-pfn-extras\n",
            "Successfully installed pytorch-pfn-extras-0.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWJPKRtfOGTh",
        "outputId": "bac81918-3a29-4486-d6c0-2585b95b2357",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Download kaggle dataset\n",
        "# NOTE: This is not the full dataset\n",
        "\n",
        "from google.colab import files\n",
        "if not os.path.exists('kaggle.json'):\n",
        "    files.upload()\n",
        "    !mkdir ~/.kaggle\n",
        "    !cp kaggle.json ~/.kaggle/\n",
        "    !chmod 600 ~/.kaggle/kaggle.json\n",
        "#!kaggle datasets list\n",
        "!kaggle config path -p /content\n",
        "\n",
        "def kaggle_dataset_download_unzip(lfilename, dir):\n",
        "\n",
        "    with zipfile.ZipFile(lfilename) as file: \n",
        "        file.extractall(dir)\n",
        "    os.remove(lfilename)\n",
        "\n",
        "dir='/content/lyft-motion'\n",
        "if not os.path.exists(dir):\n",
        "    !kaggle datasets download -d aikhmelnytskyy/liftfirst\n",
        "    lfilename='/content/liftfirst.zip'\n",
        "    kaggle_dataset_download_unzip(lfilename,dir+'/scenes')\n",
        "\n",
        "    !kaggle datasets download -d aikhmelnytskyy/lyftsecond\n",
        "    lfilename='/content/lyftsecond.zip'\n",
        "    kaggle_dataset_download_unzip(lfilename,dir)\n",
        "    \n",
        "    data_path='/content/lyft-motion/'\n",
        "    model_path='/content/drive/My Drive/Models/'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: kaggle config [-h] {view,set,unset} ...\n",
            "kaggle config: error: argument command: invalid choice: 'path' (choose from 'view', 'set', 'unset')\n",
            "Downloading liftfirst.zip to /content\n",
            "100% 15.9G/15.9G [06:34<00:00, 62.5MB/s]\n",
            "100% 15.9G/15.9G [06:35<00:00, 43.3MB/s]\n",
            "Downloading lyftsecond.zip to /content\n",
            "100% 2.33G/2.34G [00:56<00:00, 51.1MB/s]\n",
            "100% 2.34G/2.34G [00:56<00:00, 44.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhYr7dptN2VA",
        "outputId": "c183c0c3-e577-4ed9-b073-4dd1fc17576c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install l5kit"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting l5kit\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/6c/77407115fdd0543eefefd0872fe5f7433c818ed52c47d6b3d1faae77d1ee/l5kit-1.1.0-py3-none-any.whl (82kB)\n",
            "\r\u001b[K     |████                            | 10kB 25.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 20kB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 30kB 22.4MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 40kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 51kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 61kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 71kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 81kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from l5kit) (3.13)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from l5kit) (7.5.1)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.6/dist-packages (from l5kit) (3.12.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from l5kit) (1.4.1)\n",
            "Requirement already satisfied: torch<2.0.0,>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from l5kit) (1.7.0+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from l5kit) (4.41.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from l5kit) (2.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from l5kit) (3.2.2)\n",
            "Collecting pymap3d\n",
            "  Downloading https://files.pythonhosted.org/packages/8d/e8/4a175748a520b734abea0cc547a18788d979d9ae6857fa308302087d49f4/pymap3d-2.4.3.tar.gz\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from l5kit) (50.3.2)\n",
            "Collecting transforms3d\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/f7/e85809168a548a854d7c1331560c27b4f5381698d29c12e57759192b2bc1/transforms3d-0.3.1.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision<1.0.0,>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from l5kit) (0.8.1+cu101)\n",
            "Collecting zarr\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/17/37cc7afabdec7b5759d68fab0bc5afd950799a4ce2189826caf5ee087414/zarr-2.5.0-py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 22.9MB/s \n",
            "\u001b[?25hCollecting ptable\n",
            "  Downloading https://files.pythonhosted.org/packages/ab/b3/b54301811173ca94119eb474634f120a49cd370f257d1aae5a4abaf12729/PTable-0.9.2.tar.gz\n",
            "Collecting opencv-contrib-python-headless\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/aa/d0970ad362512469ee5dd7ee338e539bc6ab8658c9aaa444da72c0dac3c7/opencv_contrib_python_headless-4.4.0.46-cp36-cp36m-manylinux2014_x86_64.whl (42.9MB)\n",
            "\u001b[K     |████████████████████████████████| 42.9MB 69kB/s \n",
            "\u001b[?25hRequirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from l5kit) (5.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from l5kit) (1.18.5)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets->l5kit) (5.5.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->l5kit) (4.10.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->l5kit) (5.0.8)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->l5kit) (4.3.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->l5kit) (3.5.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.12.2->l5kit) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<2.0.0,>=1.5.0->l5kit) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch<2.0.0,>=1.5.0->l5kit) (0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch<2.0.0,>=1.5.0->l5kit) (3.7.4.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio->l5kit) (7.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->l5kit) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->l5kit) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->l5kit) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->l5kit) (0.10.0)\n",
            "Collecting fasteners\n",
            "  Downloading https://files.pythonhosted.org/packages/18/bd/55eb2d6397b9c0e263af9d091ebdb756b15756029b3cededf6461481bc63/fasteners-0.15-py2.py3-none-any.whl\n",
            "Collecting asciitree\n",
            "  Downloading https://files.pythonhosted.org/packages/2d/6a/885bc91484e1aa8f618f6f0228d76d0e67000b0fdd6090673b777e311913/asciitree-0.3.3.tar.gz\n",
            "Collecting numcodecs>=0.6.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/dc/0b7ae820c6c5f3a8b79912ec43dd9a1305e33970a05d3c02a1e8203ead9c/numcodecs-0.7.2-cp36-cp36m-manylinux2010_x86_64.whl (5.8MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8MB 28.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook->l5kit) (5.6.1)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.6/dist-packages (from notebook->l5kit) (4.6.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook->l5kit) (2.11.2)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook->l5kit) (0.9.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook->l5kit) (1.5.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook->l5kit) (0.2.0)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->l5kit) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.6/dist-packages (from notebook->l5kit) (5.3.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->l5kit) (1.0.18)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->l5kit) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->l5kit) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->l5kit) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->l5kit) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->l5kit) (0.7.5)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets->l5kit) (2.6.0)\n",
            "Collecting monotonic>=0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/aa/063eca6a416f397bd99552c534c6d11d57f58f2e94c14780f3bbf818c4cf/monotonic-1.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->l5kit) (3.2.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->l5kit) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->l5kit) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->l5kit) (1.4.3)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->l5kit) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->l5kit) (0.4.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook->l5kit) (1.1.1)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.8.1->notebook->l5kit) (0.6.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.0->notebook->l5kit) (19.0.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->l5kit) (0.2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook->l5kit) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook->l5kit) (20.4)\n",
            "Building wheels for collected packages: pymap3d\n",
            "  Building wheel for pymap3d (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pymap3d: filename=pymap3d-2.4.3-cp36-none-any.whl size=33551 sha256=856f1f060ae67b569417b101c7773e183dee21b3648260761bb742a829aba40c\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/e2/40/c642184272827b886ddb12661008199fe1460d4b05ddfc2670\n",
            "Successfully built pymap3d\n",
            "Building wheels for collected packages: transforms3d, ptable, asciitree\n",
            "  Building wheel for transforms3d (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transforms3d: filename=transforms3d-0.3.1-cp36-none-any.whl size=59374 sha256=8bc2871daf08e18a4ea6e828272ea0d64940b795ae47360b89c19028137dbc5d\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/3c/84/28d36677f3c760c048bd02b5a547ea0c4027770cc9cdb9af1e\n",
            "  Building wheel for ptable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ptable: filename=PTable-0.9.2-cp36-none-any.whl size=22905 sha256=ff0ba1c9677f596e05cbfc34bb17fef9c075dcea442bb329514af450f412858f\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/cc/2e/55980bfe86393df3e9896146a01f6802978d09d7ebcba5ea56\n",
            "  Building wheel for asciitree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for asciitree: filename=asciitree-0.3.3-cp36-none-any.whl size=5037 sha256=87ed4583cc15b9f4bb19d3d663b1c3d8497ef7ddbae4deabbffa171e14284afd\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/d9/58/9808b306744df0208fccc640d3d9952a5bc7468502d42897d5\n",
            "Successfully built transforms3d ptable asciitree\n",
            "Installing collected packages: pymap3d, transforms3d, monotonic, fasteners, asciitree, numcodecs, zarr, ptable, opencv-contrib-python-headless, l5kit\n",
            "Successfully installed asciitree-0.3.3 fasteners-0.15 l5kit-1.1.0 monotonic-1.5 numcodecs-0.7.2 opencv-contrib-python-headless-4.4.0.46 ptable-0.9.2 pymap3d-2.4.3 transforms3d-0.3.1 zarr-2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7twUR6FgTh-"
      },
      "source": [
        "# # Environment setup\n",
        "!pip install pytorch-ignite\n",
        "import os\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "import random\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- setup ---\n",
        "pd.set_option('max_columns', 50)\n",
        "\n",
        "import l5kit\n",
        "from l5kit.data import ChunkedDataset, LocalDataManager\n",
        "from l5kit.dataset import AgentDataset\n",
        "\n",
        "from l5kit.rasterization import build_rasterizer\n",
        "from l5kit.configs import load_config_data\n",
        "from l5kit.visualization import draw_trajectory, TARGET_POINTS_COLOR, PREDICTED_POINTS_COLOR\n",
        "from l5kit.geometry import transform_points\n",
        "import tqdm\n",
        "from collections import Counter\n",
        "from l5kit.data import PERCEPTION_LABELS\n",
        "from l5kit.evaluation import write_pred_csv, compute_metrics_csv, read_gt_csv, create_chopped_dataset\n",
        "from l5kit.evaluation.chop_dataset import MIN_FUTURE_STEPS\n",
        "\n",
        "from matplotlib import animation, rc\n",
        "\n",
        "import torch\n",
        "\n",
        "import pytorch_pfn_extras as ppe\n",
        "from pytorch_pfn_extras.training import IgniteExtensionsManager\n",
        "from pytorch_pfn_extras.training.triggers import MinValueTrigger\n",
        "\n",
        "from torch import nn, optim, Tensor, cuda\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Subset\n",
        "\n",
        "\n",
        "import pytorch_pfn_extras.training.extensions as E\n",
        "\n",
        "from torchvision.models import mobilenet_v2\n",
        "from typing import Dict\n",
        "\n",
        "# --- Dataset utils ---\n",
        "from typing import Callable\n",
        "\n",
        "from torch.utils.data.dataset import Dataset\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNR8doZ7kgwd"
      },
      "source": [
        "l5kit.__version__\n",
        "\n",
        "# --- Dataset utils ---\n",
        "from typing import Callable\n",
        "\n",
        "from torch.utils.data.dataset import Dataset\n",
        "\n",
        "\n",
        "class TransformDataset(Dataset):\n",
        "    def __init__(self, dataset: Dataset, transform: Callable):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch = self.dataset[index]\n",
        "        return self.transform(batch)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uphyMtZekP7i"
      },
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    \n",
        "set_seed(42)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcF3z6kkpsnv"
      },
      "source": [
        "data_path='/content/lyft-motion/'\n",
        "model_path='/content/drive/My Drive/Models/'"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-2ftCfFOT-W"
      },
      "source": [
        "# Each core on a CPU can run 2 threads\n",
        "num_workers = os.cpu_count() * 2"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaWm6dVSknfF"
      },
      "source": [
        "# --- Lyft configs ---\n",
        "\n",
        "cfg = {\n",
        "    'format_version': 4,\n",
        "    'data_path': data_path,\n",
        "    'model_params': {\n",
        "        'model_architecture': 'mobilenet_v2',\n",
        "        'history_num_frames': 5,\n",
        "        'history_step_size': 1,\n",
        "        'history_delta_time': 0.1,\n",
        "        'future_num_frames': 50,\n",
        "        'future_step_size': 1,\n",
        "        'future_delta_time': 0.1,\n",
        "        'model_name': \"model_mobilenet_baseline\",\n",
        "        'lr': 1e-3,\n",
        "        'weight_path': False,\n",
        "        'train': True,\n",
        "        'predict': False\n",
        "    },\n",
        "\n",
        "    'raster_params': {\n",
        "        'raster_size': [300, 300],\n",
        "        'pixel_size': [0.1, 0.1],\n",
        "        'ego_center': [0.5, 0.25],\n",
        "        'map_type': 'py_semantic',\n",
        "        'satellite_map_key': 'aerial_map/aerial_map.png',\n",
        "        'semantic_map_key': 'semantic_map/semantic_map.pb',\n",
        "        'dataset_meta_key': 'meta.json',\n",
        "        'filter_agents_threshold': 0.5,\n",
        "        'disable_traffic_light_faces': False\n",
        "    },\n",
        "\n",
        "    'train_data_loader': {\n",
        "        'key': 'scenes/train.zarr',\n",
        "        'batch_size': 16,\n",
        "        'shuffle': True,\n",
        "        'num_workers': num_workers\n",
        "    },\n",
        "    \n",
        "    'test_data_loader': {\n",
        "        'key': 'scenes/test.zarr',\n",
        "        'batch_size': 16,\n",
        "        'shuffle': False,\n",
        "        'num_workers': num_workers\n",
        "    },\n",
        "\n",
        "    'val_data_loader': {\n",
        "        'key': 'scenes/validate.zarr',\n",
        "        'batch_size': 16,\n",
        "        'shuffle': False,\n",
        "        'num_workers': num_workers\n",
        "    },\n",
        "\n",
        "    'train_params': {\n",
        "        'max_num_steps': 0,\n",
        "        'checkpoint_every_n_steps': 300,\n",
        "        'dataset_coverage': 0.013\n",
        "    }\n",
        "}"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2CbAbgwAOzm"
      },
      "source": [
        "flags_dict = {\n",
        "    \"debug\": True,\n",
        "    # --- Data configs ---\n",
        "    \"l5kit_data_folder\": \"/content/lyft-motion\",\n",
        "    # --- Model configs ---\n",
        "    \"pred_mode\": \"multi\",\n",
        "    # --- Training configs ---\n",
        "    \"device\": \"cuda:0\",\n",
        "    \"out_dir\": \"results/multi_train\",\n",
        "    \"epoch\": 2,\n",
        "    \"snapshot_freq\": 50,\n",
        "}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQQ1lYtAADVJ"
      },
      "source": [
        "# --- Utils ---\n",
        "import yaml\n",
        "\n",
        "\n",
        "def save_yaml(filepath, content, width=120):\n",
        "    with open(filepath, 'w') as f:\n",
        "        yaml.dump(content, f, width=width)\n",
        "\n",
        "\n",
        "def load_yaml(filepath):\n",
        "    with open(filepath, 'r') as f:\n",
        "        content = yaml.safe_load(f)\n",
        "    return content\n",
        "\n",
        "\n",
        "class DotDict(dict):\n",
        "    \"\"\"dot.notation access to dictionary attributes\n",
        "\n",
        "    Refer: https://stackoverflow.com/questions/2352181/how-to-use-a-dot-to-access-members-of-dictionary/23689767#23689767\n",
        "    \"\"\"  # NOQA\n",
        "\n",
        "    __getattr__ = dict.get\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_f7_FMNAXzK",
        "outputId": "6e991ce1-a1fb-40a2-f29d-b3c6772ab1ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "flags = DotDict(flags_dict)\n",
        "out_dir = Path(flags.out_dir)\n",
        "os.makedirs(str(out_dir), exist_ok=True)\n",
        "print(f\"flags: {flags_dict}\")\n",
        "save_yaml(out_dir / 'flags.yaml', flags_dict)\n",
        "save_yaml(out_dir / 'cfg.yaml', cfg)\n",
        "debug = flags.debug"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "flags: {'debug': True, 'l5kit_data_folder': '/content/lyft-motion', 'pred_mode': 'multi', 'device': 'cuda:0', 'out_dir': 'results/multi_train', 'epoch': 2, 'snapshot_freq': 50}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dhCsHyZnBdQ"
      },
      "source": [
        "# Train dataset/dataloader\n",
        "def transform(batch):\n",
        "    return batch[\"image\"], batch[\"target_positions\"], batch[\"target_availabilities\"]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtjyy_LsmJyr"
      },
      "source": [
        "# --- Dataset utils ---\n",
        "from typing import Callable\n",
        "\n",
        "from torch.utils.data.dataset import Dataset\n",
        "\n",
        "class TransformDataset(Dataset):\n",
        "    def __init__(self, dataset: Dataset, transform: Callable):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch = self.dataset[index]\n",
        "        return self.transform(batch)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxuIuxqYn6m4",
        "outputId": "cf5cb1f9-2563-4934-8cbc-71929cd6b016",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# set env variable for data\n",
        "os.environ[\"L5KIT_DATA_FOLDER\"] = flags.l5kit_data_folder\n",
        "dm = LocalDataManager(None)\n",
        "\n",
        "print(\"Load dataset...\")\n",
        "train_cfg = cfg[\"train_data_loader\"]\n",
        "valid_cfg = cfg[\"val_data_loader\"]\n",
        "\n",
        "# Rasterizer\n",
        "rasterizer = build_rasterizer(cfg, dm)\n",
        "\n",
        "# Train dataset/dataloader\n",
        "def transform(batch):\n",
        "    return batch[\"image\"], batch[\"target_positions\"], batch[\"target_availabilities\"]\n",
        "\n",
        "# ================= INIT TRAINING DATASET ====================\n",
        "\n",
        "train_path = \"scenes/sample.zarr\" if debug else train_cfg[\"key\"]\n",
        "train_zarr = ChunkedDataset(dm.require(train_path)).open()\n",
        "print(\"train_zarr\", type(train_zarr))\n",
        "train_agent_dataset = AgentDataset(cfg, train_zarr, rasterizer)\n",
        "train_dataset = TransformDataset(train_agent_dataset, transform)\n",
        "if debug:\n",
        "    # Only use 100 dataset for fast check...\n",
        "    train_dataset = Subset(train_dataset, np.arange(100))\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                          shuffle=train_cfg[\"shuffle\"],\n",
        "                          batch_size=train_cfg[\"batch_size\"],\n",
        "                          num_workers=train_cfg[\"num_workers\"])\n",
        "print(train_agent_dataset)\n",
        "\n",
        "# ================= INIT VALIDATION DATASET ====================\n",
        "valid_path = \"scenes/sample.zarr\" if debug else valid_cfg[\"key\"]\n",
        "valid_zarr = ChunkedDataset(dm.require(valid_path)).open()\n",
        "print(\"valid_zarr\", type(train_zarr))\n",
        "valid_agent_dataset = AgentDataset(cfg, valid_zarr, rasterizer)\n",
        "valid_dataset = TransformDataset(valid_agent_dataset, transform)\n",
        "if debug:\n",
        "    # Only use 100 dataset for fast check...\n",
        "    valid_dataset = Subset(valid_dataset, np.arange(100))\n",
        "else:\n",
        "    # Only use 1000 dataset for fast check...\n",
        "    valid_dataset = Subset(valid_dataset, np.arange(1000))\n",
        "valid_loader = DataLoader(\n",
        "    valid_dataset,\n",
        "    shuffle=valid_cfg[\"shuffle\"],\n",
        "    batch_size=valid_cfg[\"batch_size\"],\n",
        "    num_workers=valid_cfg[\"num_workers\"]\n",
        ")\n",
        "\n",
        "print(valid_agent_dataset)\n",
        "print(\"# AgentDataset train:\", len(train_agent_dataset), \"#valid\", len(valid_agent_dataset))\n",
        "print(\"# ActualDataset train:\", len(train_dataset), \"#valid\", len(valid_dataset))\n",
        "# AgentDataset train: 22496709 #valid 21624612\n",
        "# ActualDataset train: 100 #valid 100"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load dataset...\n",
            "train_zarr <class 'l5kit.data.zarr_dataset.ChunkedDataset'>\n",
            "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
            "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
            "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
            "|    100     |   24838    |  1893736   |     316008    |       0.69      |        248.38        |        76.24         |        24.83         |        10.00        |\n",
            "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
            "valid_zarr <class 'l5kit.data.zarr_dataset.ChunkedDataset'>\n",
            "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
            "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
            "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
            "|    100     |   24838    |  1893736   |     316008    |       0.69      |        248.38        |        76.24         |        24.83         |        10.00        |\n",
            "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
            "# AgentDataset train: 111634 #valid 111634\n",
            "# ActualDataset train: 100 #valid 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2byDQjz8oq_e"
      },
      "source": [
        "# --- Function utils ---\n",
        "\n",
        "def pytorch_neg_multi_log_likelihood_batch(\n",
        "    gt: Tensor, pred: Tensor, confidences: Tensor, avails: Tensor\n",
        ") -> Tensor:\n",
        "    \"\"\"\n",
        "    Compute a negative log-likelihood for the multi-modal scenario.\n",
        "    log-sum-exp trick is used here to avoid underflow and overflow, For more information about it see:\n",
        "    https://en.wikipedia.org/wiki/LogSumExp#log-sum-exp_trick_for_log-domain_calculations\n",
        "    https://timvieira.github.io/blog/post/2014/02/11/exp-normalize-trick/\n",
        "    https://leimao.github.io/blog/LogSumExp/\n",
        "    Args:\n",
        "        gt (Tensor): array of shape (bs)x(time)x(2D coords)\n",
        "        pred (Tensor): array of shape (bs)x(modes)x(time)x(2D coords)\n",
        "        confidences (Tensor): array of shape (bs)x(modes) with a confidence for each mode in each sample\n",
        "        avails (Tensor): array of shape (bs)x(time) with the availability for each gt timestep\n",
        "    Returns:\n",
        "        Tensor: negative log-likelihood for this example, a single float number\n",
        "    \"\"\"\n",
        "    assert len(pred.shape) == 4, f\"expected 3D (MxTxC) array for pred, got {pred.shape}\"\n",
        "    batch_size, num_modes, future_len, num_coords = pred.shape\n",
        "\n",
        "    assert gt.shape == (batch_size, future_len, num_coords), f\"expected 2D (Time x Coords) array for gt, got {gt.shape}\"\n",
        "    assert confidences.shape == (batch_size, num_modes), f\"expected 1D (Modes) array for gt, got {confidences.shape}\"\n",
        "    assert torch.allclose(torch.sum(confidences, dim=1), confidences.new_ones((batch_size,))), \"confidences should sum to 1\"\n",
        "    assert avails.shape == (batch_size, future_len), f\"expected 1D (Time) array for gt, got {avails.shape}\"\n",
        "    # assert all data are valid\n",
        "    assert torch.isfinite(pred).all(), \"invalid value found in pred\"\n",
        "    assert torch.isfinite(gt).all(), \"invalid value found in gt\"\n",
        "    assert torch.isfinite(confidences).all(), \"invalid value found in confidences\"\n",
        "    assert torch.isfinite(avails).all(), \"invalid value found in avails\"\n",
        "\n",
        "    # convert to (batch_size, num_modes, future_len, num_coords)\n",
        "    gt = torch.unsqueeze(gt, 1)  # add modes\n",
        "    avails = avails[:, None, :, None]  # add modes and cords\n",
        "\n",
        "    # error (batch_size, num_modes, future_len)\n",
        "    error = torch.sum(((gt - pred) * avails) ** 2, dim=-1)  # reduce coords and use availability\n",
        "\n",
        "    with np.errstate(divide=\"ignore\"):  # when confidence is 0 log goes to -inf, but we're fine with it\n",
        "        # error (batch_size, num_modes)\n",
        "        error = torch.log(confidences) - 0.5 * torch.sum(error, dim=-1)  # reduce time\n",
        "\n",
        "    # use max aggregator on modes for numerical stability\n",
        "    # error (batch_size, num_modes)\n",
        "    max_value, _ = error.max(dim=1, keepdim=True)  # error are negative at this point, so max() gives the minimum one\n",
        "    error = -torch.log(torch.sum(torch.exp(error - max_value), dim=-1, keepdim=True)) - max_value  # reduce modes\n",
        "    # print(\"error\", error)\n",
        "    return torch.mean(error)\n",
        "\n",
        "\n",
        "def pytorch_neg_multi_log_likelihood_single(\n",
        "    gt: Tensor, pred: Tensor, avails: Tensor\n",
        ") -> Tensor:\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "        gt (Tensor): array of shape (bs)x(time)x(2D coords)\n",
        "        pred (Tensor): array of shape (bs)x(time)x(2D coords)\n",
        "        avails (Tensor): array of shape (bs)x(time) with the availability for each gt timestep\n",
        "    Returns:\n",
        "        Tensor: negative log-likelihood for this example, a single float number\n",
        "    \"\"\"\n",
        "    # pred (bs)x(time)x(2D coords) --> (bs)x(mode=1)x(time)x(2D coords)\n",
        "    # create confidence (bs)x(mode=1)\n",
        "    batch_size, future_len, num_coords = pred.shape\n",
        "    confidences = pred.new_ones((batch_size, 1))\n",
        "    return pytorch_neg_multi_log_likelihood_batch(gt, pred.unsqueeze(1), confidences, avails)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTsUtIJhqA9w"
      },
      "source": [
        "class LyftMultiModel(nn.Module):\n",
        "\n",
        "    def __init__(self, cfg: Dict, num_modes=3):\n",
        "        super().__init__()\n",
        "\n",
        "        # TODO: support other than resnet18?\n",
        "        architecture = cfg['model_params']['model_architecture']\n",
        "        backbone = eval(architecture)(pretrained=True, progress=True)\n",
        "        self.backbone = backbone\n",
        "\n",
        "        num_history_channels = (cfg[\"model_params\"][\"history_num_frames\"] + 1) * 2\n",
        "        num_in_channels = 3 + num_history_channels\n",
        "\n",
        "        self.backbone.features[0][0] = nn.Conv2d(\n",
        "            num_in_channels,\n",
        "            self.backbone.features[0][0].out_channels,\n",
        "            kernel_size=self.backbone.features[0][0].kernel_size,\n",
        "            stride=self.backbone.features[0][0].stride,\n",
        "            padding=self.backbone.features[0][0].padding,\n",
        "            bias=False,\n",
        "        )\n",
        "\n",
        "        # \n",
        "        backbone_out_features = self.backbone.classifier[1].out_features\n",
        "\n",
        "        # X, Y coords for the future positions (output shape: Bx50x2)\n",
        "        self.future_len = cfg[\"model_params\"][\"future_num_frames\"]\n",
        "        num_targets = 2 * self.future_len\n",
        "\n",
        "        self.num_preds = num_targets * num_modes\n",
        "        self.num_modes = num_modes\n",
        "\n",
        "        # You can add more layers here.\n",
        "        self.head = nn.Sequential(\n",
        "            # nn.Dropout(0.2),\n",
        "            nn.Linear(in_features=backbone_out_features, out_features=self.num_preds + num_modes),\n",
        "        )\n",
        "\n",
        "     \n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        #x = torch.flatten(x, 1)\n",
        "        x = self.head(x)\n",
        "\n",
        "        # pred (bs)x(modes)x(time)x(2D coords)\n",
        "        # confidences (bs)x(modes)\n",
        "        bs, _ = x.shape\n",
        "        pred, confidences = torch.split(x, self.num_preds, dim=1)\n",
        "        pred = pred.view(bs, self.num_modes, self.future_len, 2)\n",
        "        assert confidences.shape == (bs, self.num_modes)\n",
        "        confidences = torch.softmax(confidences, dim=1)\n",
        "        return pred, confidences                            "
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UKm8u3JqvsC"
      },
      "source": [
        "class LyftMultiRegressor(nn.Module):\n",
        "    \"\"\"Single mode prediction\"\"\"\n",
        "\n",
        "    def __init__(self, predictor, lossfun=pytorch_neg_multi_log_likelihood_batch):\n",
        "        super().__init__()\n",
        "        self.predictor = predictor\n",
        "        self.lossfun = lossfun\n",
        "\n",
        "    def forward(self, image, targets, target_availabilities):\n",
        "        pred, confidences = self.predictor(image)\n",
        "        loss = self.lossfun(targets, pred, confidences, target_availabilities)\n",
        "        metrics = {\n",
        "            \"loss\": loss.item(),\n",
        "            \"nll\": pytorch_neg_multi_log_likelihood_batch(targets, pred, confidences, target_availabilities).item()\n",
        "        }\n",
        "        ppe.reporting.report(metrics, self)\n",
        "        return loss, metrics\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gUrlGrDoreW",
        "outputId": "ea7e6eaa-0eba-4962-cde9-663d4c61b3c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#predictor = LyftMultiModel(cfg)\n",
        "architecture = cfg['model_params']['model_architecture']\n",
        "model = eval(architecture)(pretrained=True, progress=True)\n",
        "#print(model.features[18].num_in_channels)\n",
        "model = LyftMultiModel(cfg)\n",
        "#print(model, \"\\n\\n\")\n",
        "print(model)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LyftMultiModel(\n",
            "  (backbone): MobileNetV2(\n",
            "    (features): Sequential(\n",
            "      (0): ConvBNReLU(\n",
            "        (0): Conv2d(15, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU6(inplace=True)\n",
            "      )\n",
            "      (1): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (2): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
            "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (3): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
            "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (4): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
            "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (5): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (6): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (7): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (8): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (9): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (10): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (11): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (12): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (13): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (14): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (15): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (16): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (17): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (18): ConvBNReLU(\n",
            "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU6(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (classifier): Sequential(\n",
            "      (0): Dropout(p=0.2, inplace=False)\n",
            "      (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (head): Sequential(\n",
            "    (0): Linear(in_features=1000, out_features=303, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dT5jM7_AtBH"
      },
      "source": [
        "device = torch.device(flags.device)\n",
        "\n",
        "if flags.pred_mode == \"multi\":\n",
        "    predictor = LyftMultiModel(cfg)\n",
        "    model = LyftMultiRegressor(predictor)\n",
        "else:\n",
        "    raise ValueError(f\"[ERROR] Unexpected value flags.pred_mode={flags.pred_mode}\")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq7imSrH_938"
      },
      "source": [
        "# --- Training utils ---\n",
        "\n",
        "from ignite.engine import Engine\n",
        "\n",
        "\n",
        "def create_trainer(model, optimizer, device) -> Engine:\n",
        "    model.to(device)\n",
        "\n",
        "    def update_fn(engine, batch):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        loss, metrics = model(*[elem.to(device) for elem in batch])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        return metrics\n",
        "    trainer = Engine(update_fn)\n",
        "    return trainer"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qtMZrLdoCay",
        "outputId": "28814b4e-5a55-43a0-bec1-eee861058272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413,
          "referenced_widgets": [
            "b0fb1ca7da644e53bbd6e55178eff1f9",
            "f33da9131af240b9b43bf6f900a8b578",
            "3bee99105c014128b1361dbc546617d5",
            "973f99c5c13e402e8bfaadce782f3c4b",
            "9bb5a01b8ba14e20b5604878672477b0",
            "9941af77058044cc9ac3607c4da2d557",
            "fc5680a472004a298874666228ac7018",
            "975673260de1444ba1a3981ea47e3995",
            "31082019486749e3980d3ae419ddaf79",
            "250a340b1a7646338aac811d149534cf",
            "f8214b5cc8004a1c97be04ba577b49e7",
            "9c2f2e023caf41f1969731fa45c5071e",
            "5a2a81540b23475999331ef3c52dd012",
            "106197aabbf444d98df8c0d87ffccbe8",
            "e0bee1ddbf2547378a658414f616288c",
            "8d738215d4df46619b8e38cedd544479",
            "b6993d57ad824ec58ef1a931c44fec02",
            "e4164d82b76648208cd7612081f7a97b",
            "3263c840b5a646d49b7eec0dc05ed88c",
            "1bad5529215d4d3591ca5e6db2027ed9",
            "a640772fbee34f19bf76cfc0140e083d",
            "56a71fb57eb744f39ee99f7ee4d3f1ea",
            "01cb0aa70102447b93463cfcb9b7dda8",
            "da82d683ad82442bbeb85ea3a1a9fdc8"
          ]
        }
      },
      "source": [
        "# Train setup\n",
        "trainer = create_trainer(model, optimizer, device)\n",
        "\n",
        "\n",
        "def eval_func(*batch):\n",
        "    loss, metrics = model(*[elem.to(device) for elem in batch])\n",
        "\n",
        "\n",
        "valid_evaluator = E.Evaluator(\n",
        "    valid_loader,\n",
        "    model,\n",
        "    progress_bar=False,\n",
        "    eval_func=eval_func,\n",
        ")\n",
        "\n",
        "log_trigger = (10 if debug else 1000, \"iteration\")\n",
        "log_report = E.LogReport(trigger=log_trigger)\n",
        "\n",
        "\n",
        "extensions = [\n",
        "    log_report,  # Save `log` to file\n",
        "    valid_evaluator,  # Run evaluation for valid dataset in each epoch.\n",
        "    # E.FailOnNonNumber()  # Stop training when nan is detected.\n",
        "    E.ProgressBarNotebook(update_interval=10 if debug else 100),  # Show progress bar during training\n",
        "    E.PrintReportNotebook(),  # Show \"log\" on jupyter notebook  \n",
        "]\n",
        "\n",
        "epoch = flags.epoch\n",
        "\n",
        "models = {\"main\": model}\n",
        "optimizers = {\"main\": optimizer}\n",
        "manager = IgniteExtensionsManager(\n",
        "    trainer,\n",
        "    models,\n",
        "    optimizers,\n",
        "    epoch,\n",
        "    extensions=extensions,\n",
        "    out_dir=str(out_dir),\n",
        ")\n",
        "# Save predictor.pt every epoch\n",
        "manager.extend(E.snapshot_object(predictor, f\"predictor_{cfg['model_params']['model_name']}.pt\"),\n",
        "               trigger=(flags.snapshot_freq, \"iteration\"))\n",
        "# Check & Save best validation predictor.pt every epoch\n",
        "# manager.extend(E.snapshot_object(predictor, \"best_predictor.pt\"),\n",
        "#                trigger=MinValueTrigger(\"validation/main/nll\", trigger=(flags.snapshot_freq, \"iteration\")))\n",
        "# --- lr scheduler ---\n",
        "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "#     optimizer, mode='min', factor=0.7, patience=5, min_lr=1e-10)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
        "    optimizer, gamma=0.99999)\n",
        "manager.extend(lambda manager: scheduler.step(), trigger=(1, \"iteration\"))\n",
        "# Show \"lr\" column in log\n",
        "manager.extend(E.observe_lr(optimizer=optimizer), trigger=log_trigger)\n",
        "\n",
        "# --- HACKING to fix ProgressBarNotebook bug ---\n",
        "manager.iteration = 0\n",
        "manager._iters_per_epoch = len(train_loader)\n",
        "\n",
        "trainer.run(train_loader, max_epochs=epoch)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0fb1ca7da644e53bbd6e55178eff1f9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(HBox(children=(FloatProgress(value=0.0, bar_style='info', description='total', max=1.0), HTML(v…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56a71fb57eb744f39ee99f7ee4d3f1ea",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HTML(value='')"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "State:\n",
              "\titeration: 14\n",
              "\tepoch: 2\n",
              "\tepoch_length: 7\n",
              "\tmax_epochs: 2\n",
              "\toutput: <class 'dict'>\n",
              "\tbatch: <class 'list'>\n",
              "\tmetrics: <class 'dict'>\n",
              "\tdataloader: torch.utils.data.dataloader.DataLoader\n",
              "\tseed: <class 'NoneType'>\n",
              "\ttimes: <class 'dict'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw74MxgxBBbG"
      },
      "source": [
        "df = log_report.to_dataframe()\n",
        "df.to_csv(out_dir/\"log.csv\", index=False)\n",
        "df[[\"epoch\", \"iteration\", \"main/loss\", \"main/nll\", \"validation/main/loss\", \"validation/main/nll\", \"lr\", \"elapsed_time\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZtXn1O1rI83",
        "outputId": "2918282a-2a07-437a-f581-6780224320b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(model)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LyftMultiModel(\n",
            "  (backbone): ResNet(\n",
            "    (conv1): Conv2d(25, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            "  )\n",
            "  (head): Sequential(\n",
            "    (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
            "  )\n",
            "  (logit): Linear(in_features=4096, out_features=303, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aWWFhpG6qLF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}